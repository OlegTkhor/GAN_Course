{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OlegTkhor/GAN_Course/blob/main/Simple_GAN_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super().__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            nn.Linear(in_features, 128),\n",
        "            nn.LeakyReLU(0.01),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.LeakyReLU(0.01),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.disc(x)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim, img_dim):\n",
        "        super().__init__()\n",
        "        self.gen = nn.Sequential(\n",
        "            nn.Linear(z_dim, 256),\n",
        "            nn.LeakyReLU(0.01),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.LeakyReLU(0.01),\n",
        "            nn.Linear(256, img_dim),\n",
        "            nn.Tanh(),  # normalize inputs to [-1, 1] so make outputs [-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.gen(x)\n",
        "\n",
        "\n",
        "# Hyperparameters etc.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "lr = 3e-4\n",
        "z_dim = 64\n",
        "image_dim = 28 * 28 * 1  # 784\n",
        "batch_size = 32\n",
        "num_epochs = 50\n",
        "\n",
        "disc = Discriminator(image_dim).to(device)\n",
        "gen = Generator(z_dim, image_dim).to(device)\n",
        "fixed_noise = torch.randn((batch_size, z_dim)).to(device)\n",
        "transforms = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),]\n",
        ")\n",
        "\n",
        "dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)\n",
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
        "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
        "criterion = nn.BCELoss()\n",
        "writer_fake = SummaryWriter(f\"logs/fake\")\n",
        "writer_real = SummaryWriter(f\"logs/real\")\n",
        "step = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (real, _) in enumerate(loader):\n",
        "        real = real.view(-1, 784).to(device)\n",
        "        batch_size = real.shape[0]\n",
        "\n",
        "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
        "        noise = torch.randn(batch_size, z_dim).to(device)\n",
        "        fake = gen(noise)\n",
        "        disc_real = disc(real).view(-1)\n",
        "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
        "        disc_fake = disc(fake).view(-1)\n",
        "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
        "        lossD = (lossD_real + lossD_fake) / 2\n",
        "        disc.zero_grad()\n",
        "        lossD.backward(retain_graph=True)\n",
        "        opt_disc.step()\n",
        "\n",
        "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
        "        # where the second option of maximizing doesn't suffer from\n",
        "        # saturating gradients\n",
        "        output = disc(fake).view(-1)\n",
        "        lossG = criterion(output, torch.ones_like(output))\n",
        "        gen.zero_grad()\n",
        "        lossG.backward()\n",
        "        opt_gen.step()\n",
        "\n",
        "        if batch_idx == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\n",
        "                      Loss D: {lossD:.4f}, loss G: {lossG:.4f}\"\n",
        "            )\n",
        "\n",
        "            with torch.no_grad():\n",
        "                fake = gen(fixed_noise).reshape(-1, 1, 28, 28)\n",
        "                data = real.reshape(-1, 1, 28, 28)\n",
        "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
        "                img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n",
        "\n",
        "                writer_fake.add_image(\n",
        "                    \"Mnist Fake Images\", img_grid_fake, global_step=step\n",
        "                )\n",
        "                writer_real.add_image(\n",
        "                    \"Mnist Real Images\", img_grid_real, global_step=step\n",
        "                )\n",
        "                step += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWjhSXPeQ_Mq",
        "outputId": "ca61c7f2-0b77-43f6-df57-83af72a89103"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/50] Batch 0/1875                       Loss D: 0.6588, loss G: 0.6802\n",
            "Epoch [1/50] Batch 0/1875                       Loss D: 0.2183, loss G: 2.3148\n",
            "Epoch [2/50] Batch 0/1875                       Loss D: 0.8051, loss G: 0.7533\n",
            "Epoch [3/50] Batch 0/1875                       Loss D: 0.3384, loss G: 1.7312\n",
            "Epoch [4/50] Batch 0/1875                       Loss D: 0.5679, loss G: 1.2845\n",
            "Epoch [5/50] Batch 0/1875                       Loss D: 0.3975, loss G: 1.2361\n",
            "Epoch [6/50] Batch 0/1875                       Loss D: 0.3391, loss G: 1.5317\n",
            "Epoch [7/50] Batch 0/1875                       Loss D: 0.6901, loss G: 1.0148\n",
            "Epoch [8/50] Batch 0/1875                       Loss D: 0.3884, loss G: 1.9639\n",
            "Epoch [9/50] Batch 0/1875                       Loss D: 0.3978, loss G: 2.8892\n",
            "Epoch [10/50] Batch 0/1875                       Loss D: 0.4426, loss G: 1.8866\n",
            "Epoch [11/50] Batch 0/1875                       Loss D: 0.3094, loss G: 3.0847\n",
            "Epoch [12/50] Batch 0/1875                       Loss D: 0.6664, loss G: 2.2940\n",
            "Epoch [13/50] Batch 0/1875                       Loss D: 0.2949, loss G: 1.7703\n",
            "Epoch [14/50] Batch 0/1875                       Loss D: 0.4260, loss G: 1.2093\n",
            "Epoch [15/50] Batch 0/1875                       Loss D: 0.5327, loss G: 1.5356\n",
            "Epoch [16/50] Batch 0/1875                       Loss D: 0.5260, loss G: 1.3605\n",
            "Epoch [17/50] Batch 0/1875                       Loss D: 0.2399, loss G: 2.3824\n",
            "Epoch [18/50] Batch 0/1875                       Loss D: 0.3621, loss G: 1.7473\n",
            "Epoch [19/50] Batch 0/1875                       Loss D: 0.5513, loss G: 1.5014\n",
            "Epoch [20/50] Batch 0/1875                       Loss D: 0.4223, loss G: 1.4385\n",
            "Epoch [21/50] Batch 0/1875                       Loss D: 0.3720, loss G: 1.6077\n",
            "Epoch [22/50] Batch 0/1875                       Loss D: 0.6132, loss G: 1.8213\n",
            "Epoch [23/50] Batch 0/1875                       Loss D: 0.4743, loss G: 1.5257\n",
            "Epoch [24/50] Batch 0/1875                       Loss D: 0.3717, loss G: 1.5654\n",
            "Epoch [25/50] Batch 0/1875                       Loss D: 0.4558, loss G: 1.3875\n",
            "Epoch [26/50] Batch 0/1875                       Loss D: 0.6490, loss G: 1.5496\n",
            "Epoch [27/50] Batch 0/1875                       Loss D: 0.4728, loss G: 1.2653\n",
            "Epoch [28/50] Batch 0/1875                       Loss D: 0.4631, loss G: 1.1458\n",
            "Epoch [29/50] Batch 0/1875                       Loss D: 0.4536, loss G: 1.2563\n",
            "Epoch [30/50] Batch 0/1875                       Loss D: 0.5342, loss G: 1.3901\n",
            "Epoch [31/50] Batch 0/1875                       Loss D: 0.5289, loss G: 1.1304\n",
            "Epoch [32/50] Batch 0/1875                       Loss D: 0.5059, loss G: 1.1403\n",
            "Epoch [33/50] Batch 0/1875                       Loss D: 0.5451, loss G: 1.3690\n",
            "Epoch [34/50] Batch 0/1875                       Loss D: 0.5187, loss G: 1.2407\n",
            "Epoch [35/50] Batch 0/1875                       Loss D: 0.6028, loss G: 0.9783\n",
            "Epoch [36/50] Batch 0/1875                       Loss D: 0.4874, loss G: 0.9753\n",
            "Epoch [37/50] Batch 0/1875                       Loss D: 0.4980, loss G: 1.2948\n",
            "Epoch [38/50] Batch 0/1875                       Loss D: 0.6315, loss G: 1.1262\n",
            "Epoch [39/50] Batch 0/1875                       Loss D: 0.5506, loss G: 1.0164\n",
            "Epoch [40/50] Batch 0/1875                       Loss D: 0.5565, loss G: 1.0060\n",
            "Epoch [41/50] Batch 0/1875                       Loss D: 0.5300, loss G: 1.2236\n",
            "Epoch [42/50] Batch 0/1875                       Loss D: 0.6140, loss G: 0.9405\n",
            "Epoch [43/50] Batch 0/1875                       Loss D: 0.5356, loss G: 1.2188\n",
            "Epoch [44/50] Batch 0/1875                       Loss D: 0.5693, loss G: 0.8782\n",
            "Epoch [45/50] Batch 0/1875                       Loss D: 0.6131, loss G: 1.0102\n",
            "Epoch [46/50] Batch 0/1875                       Loss D: 0.4225, loss G: 1.4918\n",
            "Epoch [47/50] Batch 0/1875                       Loss D: 0.5668, loss G: 0.9759\n",
            "Epoch [48/50] Batch 0/1875                       Loss D: 0.7105, loss G: 0.8340\n",
            "Epoch [49/50] Batch 0/1875                       Loss D: 0.6703, loss G: 1.0363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = gen(fixed_noise)"
      ],
      "metadata": {
        "id": "2eVFyjCVWbyv"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "result = output[11].view(28,28).detach().numpy()\n",
        "plt.imshow(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Uzo95X3xW3PN",
        "outputId": "1a3e2853-66d1-47a4-eccb-2ac321e8c649"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f88fb7fdf90>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAR4UlEQVR4nO3dfWxd5X0H8O/X145N3u0EghsiQqKkLJ1oYFbYCmXpIrIAqoBKRU01lEpoRhovpas0EJtWqmkSW1doVVXVQokaNpoOrdBkGlDSlCnqqmYYloa8AHkhWeKGJDRSnDfHvr6//eEDNeDnd5x77r3nOM/3I1m+Pr/73PP4+H597r3POeehmUFELnxNeXdARBpDYReJhMIuEgmFXSQSCrtIJJobubIJbLU2TGrkKseO9Ov1HLVIWTU0YCJj1I/TGLBzoz6jMoWd5AoA3wZQAvB9M3vUu38bJuFaLsuyyrpha6tbt3Pn6rfuZv/PYOVy3dY9ruX5D7qgttimYK3ql/EkSwC+C+AmAIsArCS5qNrHE5H6yvKefQmAPWa2z8wGAPwIwK216ZaI1FqWsM8GcHDEz4eSZR9AsptkD8meQdTvpbCI+Or+abyZrTazLjPraoH/vlhE6idL2HsBzBnx82XJMhEpoCxhfwXAApJXkJwA4AsANtSmWyJSa1UPvZlZmeS9AH6K4aG3NWa2o2Y9a7B6Dq2lrltDa9UZx0Nr3nBrvZ4PmcbZzex5AM/XqC8iUkc6XFYkEgq7SCQUdpFIKOwikVDYRSKhsItEoqHns8s4lHIaaWn+XLdeORA+qNLKg5kem6fOuPXyO0fcehZZT4k+vv6KYK39s/v8lVeG/HqA9uwikVDYRSKhsItEQmEXiYTCLhIJhV0kEg0demOpCaXJU4P1ob4+/wGaSuFa2nBE2pVImfJ/z3n80oJ5btOh3SlDKd7vlbLuVCm/N5tb/PZWccve0BoAlC69JFgrd7b76z7lD18d/OJ8tz77ifDQXOXkSX/dKdutabJ/SfShlKG39lt2V73uamnPLhIJhV0kEgq7SCQUdpFIKOwikVDYRSKhsItEoqHj7DZUSR9L92QZb0677LBV/9ip4+hpsvxeaVJ+bxsc8NunneI6zR9vPvXJjwVrvV/01/3DP3rara9cf59b56UXh4tp4+wpKif85zFbJrh1d7vX6RLZ2rOLREJhF4mEwi4SCYVdJBIKu0gkFHaRSCjsIpHQpaTFxZJ/rn150Vy3fvs/vBSsDZr/2N/6zXK33jTgHwMwtPdAuO2UKf5jT5/m1ssHD7n1IsoUdpL7AZwEMASgbGZdteiUiNReLfbsnzGzd2vwOCJSR3rPLhKJrGE3AC+RfJVk92h3INlNsodkzyD863KJSP1kfRl/vZn1krwEwEaSb5jZ5pF3MLPVAFYDwFR21OcIfxFJlWnPbma9yfejAJ4DsKQWnRKR2qs67CQnkZzy3m0AywFsr1XHRKS2sryMnwXgOQ6f79wM4Idm9mJNeiWFkTYefXzhRLe+58ysYO3+S37utn395Gy3Pv8Z/5x0c64TkHbd+NTryo9DVYfdzPYB+GQN+yIidaShN5FIKOwikVDYRSKhsItEQmEXicSFc4prPac9voCVZnS49d4/u9KtT7v5sFv/+87/CtbeHvSffr/c50/JvHDvfreuv/gHac8uEgmFXSQSCrtIJBR2kUgo7CKRUNhFIqGwi0TiwhlnTxtHT5l6uF7T5OYtberg4zctdOtrH3jcrX9igv8UOuNs1o7SoNv2oon+Zcw4dbJbL01oCdaGjhx1216ItGcXiYTCLhIJhV0kEgq7SCQUdpFIKOwikVDYRSIxrsbZ2RzurpXLfuMLdBwdgHsMQWn2pW7TT//lFreeNo6e5qRz/MNNr9zttl0xd5dbfwP+paZP/PG8YG3ai/1u28pZv26DA269iMd1aM8uEgmFXSQSCrtIJBR2kUgo7CKRUNhFIqGwi0RiXI2zp46lX6DSzklv6pgerN34n9vctvdN3+fWS/Svx3906LRbn+Jcz39g71S37cbSx936xU/66z7zbHhfNm3WTLet7Xnbracq4HEdqXt2kmtIHiW5fcSyDpIbSe5OvrfXt5siktVYXsb/AMCKDy17CMAmM1sAYFPys4gUWGrYzWwzgOMfWnwrgLXJ7bUAbqtxv0Skxqp9zz7LzN6b5OsdALNCdyTZDaAbANowscrViUhWmT+NNzMDEPw0wsxWm1mXmXW1oDXr6kSkStWG/QjJTgBIvsd3qU6RcabasG8AsCq5vQrA+tp0R0TqJfU9O8l1AJYCmEnyEICvAXgUwDMk7wJwAMAd9exk7Nji/5l2fX1usPYf019025aY7Z3cZIavzQ4AL/eHx9L/4Lo33bZ9A21ufeFU/wXlZguf785TZ9y2dR8n9853T1u32zZcSg27ma0MlJaltRWR4tDhsiKRUNhFIqGwi0RCYReJhMIuEolxdYqryzmVEkD6lM71lHJZYTb7w1dLtxxz6z/p+G6wVkoZGhuyiluveGM5AE5U/Esq9w52BGu7jgWPsgYA3HL5Dre+s6/TrU85GP6b2+ScD93OMrRXZVvt2UUiobCLREJhF4mEwi4SCYVdJBIKu0gkFHaRSFw44+x5jqOnSTmNdN9Tv+fW/739n916M8KXmk4bR99bPuvWN56+0q1vO3WZW29heP3fuWqd2/aaCf60yf0z/b/555q/EqydnT/DbTtht3+J7fFIe3aRSCjsIpFQ2EUiobCLREJhF4mEwi4SCYVdJBIXzjh7nlLOV9+z9iq3/sYN33frLfQvqXyqEh6P/tbxxW7bDY99xq2nnM6OqQfOufV9Xwpvm79d9nO3bWvK791v/jj7bz4/GKzNv9OfyrrImtrC24X94e2tPbtIJBR2kUgo7CKRUNhFIqGwi0RCYReJhMIuEgmNs9dAaVp4WmIAeLjrBbe+Z9Afq/5Ysz+O/+Zg+M/433de7badsfvXbr3S7/ctzYLN4dqn/vUet+22G1a79fami9z68oW7grX9kye5bYf6+tx6nir94eMqzLmmfOqeneQakkdJbh+x7BGSvSS3Jl83n2+HRaSxxvIy/gcAVoyy/HEzW5x8PV/bbolIraWG3cw2AzjegL6ISB1l+YDuXpLbkpf57aE7kewm2UOyZxDZ3v+JSPWqDfv3AMwHsBjAYQDfDN3RzFabWZeZdbWgtcrViUhWVYXdzI6Y2ZCZVQA8AWBJbbslIrVWVdhJjpwr93YA20P3FZFiSB1nJ7kOwFIAM0keAvA1AEtJLsbw2c77Adxdxz6+r/nyOcFa+cDBRnRhVG/8nX9t9bX/F56jHAC+ceJGt77y46+69S2fD193vvJWeKy5IZxz/Zv3+OPkZz4dPh8dAAbhn89+edtvg7W9p/xjIwqtqRSuOZskNexmtnKUxU+OoUsiUiA6XFYkEgq7SCQUdpFIKOwikVDYRSJRqFNcmy+b7dbd4TVvOALIPqWz8/hsH3CbPjjfP8X1b3bc5tZ/da0/TFTp3+vW81SaPj1Y6/7cT922U5rCU1EDwL+d7HTrL/zV0mCt1XrctoVW5XNZe3aRSCjsIpFQ2EUiobCLREJhF4mEwi4SCYVdJBKFGmcvH+qtvrFVsq08Zdrl0sUzgrXKaX8z7h+42K1ftC48Fg34lweut+bOS936W1+5wq3ff0v4WqR/Mf1tt+3ZlCmZv97zWbe+YOP/Bmt5blMA/nEhWY8JCa2yLo8qIoWjsItEQmEXiYTCLhIJhV0kEgq7SCQUdpFIFGqcPROm/N9KGbNFyrgrJ00M11r9Mf5PtPrHDxxe6refvtGfXthrzZTjBw7dd41b33T/N9z6jJRpk0vO32UoZaj72FDZrV/54BG3Xi777XOV9biQKmjPLhIJhV0kEgq7SCQUdpFIKOwikVDYRSKhsItEYlyNs5+9bUmwdtFP/ifbg6dcd94uag3Wbly0023bUTrj1p/70++49bf+5BK33sbw1Mafajvmtp1Z+pVbB/wx/jRnKuFr6j92/Cq37S+XhafoBoChdw9X1adCyOF8+tQ9O8k5JF8muZPkDpJfTpZ3kNxIcnfyvb3+3RWRao3lZXwZwFfNbBGAPwRwD8lFAB4CsMnMFgDYlPwsIgWVGnYzO2xmryW3TwLYBWA2gFsBrE3uthaAP4eRiOTqvN6zk5wL4GoAWwDMMrP33jS9A2BWoE03gG4AaEP4+HIRqa8xfxpPcjKAHwN4wMz6RtZs+Op9o37iYGarzazLzLpaEP6QS0Tqa0xhJ9mC4aA/bWbPJouPkOxM6p0AjtaniyJSC6kv4zl8juSTAHaZ2WMjShsArALwaPJ9/ZjW6J1ymTIckWV4jS3+9L826E+7XJ7WFqy1NvmnUs5L2cqTm/xXPItbT/gP4Mo2dDaYcmrwwhfuduvz1oX/ps2bXk1Zuz9sKOdnLO/ZrwNwJ4DXSW5Nlj2M4ZA/Q/IuAAcA3FGfLopILaSG3cx+ASC0O15W2+6ISL3ocFmRSCjsIpFQ2EUiobCLREJhF4kEGzl17VR22LWs0wf4KaeoZp4G13n85s5RjxR+385HZrv1ny1/3K1Pa/IvBz2lKXwMwa4B/5LFt2+6x61fee92t17p73fr0lhbbBP67PioTxjt2UUiobCLREJhF4mEwi4SCYVdJBIKu0gkFHaRSDR+nL20PHyHrGPhGZRmznDrQ+/+NlhrmpQypfIZ/1LSpUUL/XXv2uPW3el/c7hkseRH4+wiorCLxEJhF4mEwi4SCYVdJBIKu0gkFHaRSDR+yuYMY+lsDne3aaI/tdRQX59fd8bR01ROn666LQAM7XgzU3uRsdCeXSQSCrtIJBR2kUgo7CKRUNhFIqGwi0RCYReJxFjmZ58D4CkAswAYgNVm9m2SjwD4c/xuEu2Hzez5enUUAKwcngc9bRxdpFDS5jnwVHmsylgOqikD+KqZvUZyCoBXSW5Mao+b2T9VtWYRaaixzM9+GMDh5PZJkrsA+FOciEjhnNd7dpJzAVwNYEuy6F6S20iuIdkeaNNNsodkzyDOZeqsiFRvzGEnORnAjwE8YGZ9AL4HYD6AxRje839ztHZmttrMusysqwWtNeiyiFRjTGEn2YLhoD9tZs8CgJkdMbMhM6sAeALAkvp1U0SySg07SQJ4EsAuM3tsxPLOEXe7HYA/3aeI5Gosn8ZfB+BOAK+T3JosexjASpKLMTwctx/A3WNaozfkkOOlpEUaKofn+lg+jf8FgNGuQ13XMXURqS0dQScSCYVdJBIKu0gkFHaRSCjsIpFQ2EUiMa4uJe3iqLPU/k6eUxcXuW8ZeZf3BvzTkjOd5gnouIzzpD27SCQUdpFIKOwikVDYRSKhsItEQmEXiYTCLhIJWgPHeEkeA3BgxKKZAN5tWAfOT1H7VtR+AepbtWrZt8vN7OLRCg0N+0dWTvaYWVduHXAUtW9F7RegvlWrUX3Ty3iRSCjsIpHIO+yrc16/p6h9K2q/APWtWg3pW67v2UWkcfLes4tIgyjsIpHIJewkV5B8k+Qekg/l0YcQkvtJvk5yK8menPuyhuRRkttHLOsguZHk7uT7qHPs5dS3R0j2JttuK8mbc+rbHJIvk9xJcgfJLyfLc912Tr8ast0a/p6dZAnAWwBuBHAIwCsAVprZzoZ2JIDkfgBdZpb7ARgkbwBwCsBTZvb7ybJ/BHDczB5N/lG2m9mDBenbIwBO5T2NdzJbUefIacYB3AbgS8hx2zn9ugMN2G557NmXANhjZvvMbADAjwDcmkM/Cs/MNgM4/qHFtwJYm9xei+EnS8MF+lYIZnbYzF5Lbp8E8N4047luO6dfDZFH2GcDODji50Mo1nzvBuAlkq+S7M67M6OYZWaHk9vvAJiVZ2dGkTqNdyN9aJrxwmy7aqY/z0of0H3U9WZ2DYCbANyTvFwtJBt+D1aksdMxTePdKKNMM/6+PLddtdOfZ5VH2HsBzBnx82XJskIws97k+1EAz6F4U1EfeW8G3eT70Zz7874iTeM92jTjKMC2y3P68zzC/gqABSSvIDkBwBcAbMihHx9BclLywQlITgKwHMWbinoDgFXJ7VUA1ufYlw8oyjTeoWnGkfO2y336czNr+BeAmzH8ifxeAH+dRx8C/ZoH4NfJ1468+wZgHYZf1g1i+LONuwDMALAJwG4APwPQUaC+/QuA1wFsw3CwOnPq2/UYfom+DcDW5OvmvLed06+GbDcdLisSCX1AJxIJhV0kEgq7SCQUdpFIKOwikVDYRSKhsItE4v8BfQVrjd6VXioAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Welcome To Colaboratory",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}